## Asymptotic Analysis
- As we know that data structure is a way of organizing the data efficiently and that efficiency is measured either in terms of time or space. So, the ideal data structure is a structure that occupies the least possible time to perform all its operation and the memory space. Our focus would be on finding the time complexity rather than space complexity, and by finding the time complexity, we can decide which data structure is the best for an algorithm.

### Two major fector Depends Asymptotic Analysis :
- Time Complexity
- space complexity

>Worst case: It defines the input for which the algorithm takes a higher time.

>Average case: It takes average time for the program execution.

>Best case: It defines the input for which the algorithm takes the lowest time
___
## Time Complexity :
- Time complexity can be defined as the amount of time taken by an algorithm to execute each statement of code of an algorithm till its completion with respect to the function of the length of the input
- 
## Overview

- Whenever we are thinking of a solution to a problem, there can be N number of solutions. For instance, any problem can be solved in multiple different ways. But the Question that arises here is, how can we recognize the most efficient solution if we have a set of different solutions?

- To answer this question let us understand What is Time Complexity? Through this article we shall also cover the different notations to calculate time complexity.

- Let us consider a simple example to understand what we we are trying to figure out. Let us say we want to find square of a number. Now to check that let us suppose we have two approaches. The first approach towards this problem would be to simply use the mathematical operator * to find the square.

- On the other hand, the second approach towards finding the solution would be to run a loop of 'n' times which starts with the number 'n' and then we gradually keep adding 'n' to it everytime. Now it is clearly understood that if we execute both the approach, both will take different time to execute and give output. And in this case, the first approach will take less time and hence is said to be the efficient way.
___
### What is Time Complexity?
- To answer this question first we must keep in mind that for number of problems that must be solved using an algorithm, there can be infinte number of solutions. And it then becomes important to do the analysis of algorithms to find the most efficient solution for solving that problem.

Now to know which solution is the most efficient one, the concept of space and time complexity of algorithms comes into picture.

The Space and Time complexity can be defined as a measurement scale for algorithms where we compare the algorithms on the basis of their Space (i.e. the amount of memory it utilises ) and the Time complexity (i.e. the number of operations it runs to find the solution).

There can more than one way to solve the problem in programming, but knowing how which of the algorithm works efficiently and hence, can add value to the way we do programming .

So, in order to dive deep to find the effectiveness of the program, we must know how to evaluate them using the Space and Time complexity. This use of Space and Time complexity can help us make the program behave according to the required optimal conditions, which in some way makes us an efficient programmers too. As with this module we are focussing more on the Time Complexity domain let us take a look at the definition of the same.

- The Time complexity of algorithms is most commonly expressed using the big O notation. It's an asymptotic notation to represent the time complexity.
- The Time Complexity can also be elaborated by estimating the counts of the number of elementary steps that are performed by any algorithm to finish the execution. As we saw in above example where we shared the two approaches to find a square of a number, then with the first approach the time taken will remain constant while for the second it varies with respect to the 'n' that runs on the loop to give an output.

It should also be noted that as the algorithm's performance varies with respect to the multiple types of input data, so we usually we also keep a check for the worst-case scenario for an algorithm so that we are well aware of the maximum time taken for any input size.

Summing up above points, we can concude that the time complexity is explained as the number of operations an algorithm performs in order to complete a task with respect to the size of the input. And to find out which algorithm must be considered as the most efficient one, we pick the one which takes the smallest number of operations in terms of the time complexity.
___

## Asymptotic Notations :
- Asymptotic notations are the mathematical notations used to describe the running time of an algorithm when the input tends towards a particular value or a limiting value.

For example: In bubble sort, when the input array is already sorted, the time taken by the algorithm is linear i.e. the best case.

But, when the input array is in reverse condition, the algorithm takes the maximum time (quadratic) to sort the elements i.e. the worst case.

When the input array is neither sorted nor in reverse order, then it takes average time. These durations are denoted using asymptotic notations.

- Asymptotic notation is a mathematical notation that is used to analyze the time complexity and the runtime of an algorithm for a large input.
- In order to analyze the performance of our algorithm for different inputs, we are required to find how much time it takes to run when different inputs are provided to it. One can simply calculate this time manually. But calculating the runtime of an algorithm manually is not a good idea because sometimes, it is not possible for humans to record such a small runtime.

### here are mainly three asymptotic notations:
- Big-O Notation (O-notation)
- Omega Notation (Ω-notation)
- Theta Notation (Θ-notation)
___
## Big-O Notation (O-notation)
### What is Big O Notation in Data Structure?

- Big O Notation in Data Structure is used to express algorithmic complexity using algebraic terms. It describes the upper bound of an algorithm's runtime and calculates the time and amount of memory needed to execute the algorithm for an input value.
___
### What is Big-O Notation(O-Notation)?
- The Big-O notation is used to define if the set of functions is going to grow slower than or at the same rate with respect to the expression. This is how we define the worst case of an algorithm's time complexity. This also elaborates on the the maximum amount of time required by an algorithm considering all input values.
##### Examples: 
- Runtime Complexity for Linear Search – O(n)
- Runtime Complexity for Binary Search – O(log n)
- Runtime Complexity for Bubble Sort, Selection Sort, Insertion Sort, Bucket Sort - O(n^c).
- Runtime Complexity for Exponential algorithms like Tower of Hanoi - O(c^n).
- Runtime Complexity for Heap Sort, Merge Sort - O(n log n).
___
### Why do we need Big O?

- The world we live in today consists of complicated apps and software, each running on various devices and each having different capabilities. Some devices like desktops can run heavy machine learning software, but others like phones can only run apps. So when you create an application, you’ll need to optimize your code so that it runs smoothly across devices to give you an edge over your competitors.

As a result, programmers should inspect and evaluate their code thoroughly. 
___
### What is Time Complexity?

- The time complexity, computational complexity or temporal complexity describes the amount of time necessary to execute an algorithm. It is not a measure of the actual time taken to run an algorithm, instead, it is a measure of how the time taken scales with change in the input length. As a result, the size and magnitude of the processed data have a significant impact. Moreover, It also aids in defining an algorithm's usefulness and evaluating its performance.
___
### What is Space Complexity?

- The overall amount of memory or space utilized by an algorithm/program, including the space of input values for execution, is called space complexity. To determine space complexity, simply compute how much space the variables in an algorithm/a program take up.

- People usually confuse auxiliary space with space complexity. Auxiliary space is not the equivalent of space complexity, but it’s a part of it. Auxiliary space is just the temporary or extra space, whereas space complexity also includes space used by input values.

Put simply,

>Space Complexity = Auxiliary space + Space used by input values.

- The best algorithms/programs should have the least space complexity. The lesser the space used, the faster it executes.

- Ideally, space and time complexities depend on various factors, such as underlying hardware, OS, CPU, processor, etc. But to keep things simple, we typically don’t consider these factors when analyzing an algorithm's performance.

- Following are the key time and space complexities:
  - Constant: O(1)
  - Linear time: O(n)
  - Logarithmic time: O(n log n)
  - Quadratic time: O(n^2)
  - Exponential time: 2 ^(n)
  - Factorial time: O(n!)

___
### What are the rules of using Big O notation? 
- Worst Case
- Upper Bound</br>

<div align = "center"> <img src="https://media.geeksforgeeks.org/wp-content/uploads/AlgoAnalysis-2.png"></div></br>

Let f(n) and g(n) be two functions dependent on the input variable n. So, the function f(n)=O(g(n)) if there exists some positive constants c and n′ 
such that f(n) <= c.g(n) for all n>=n′.</br>
F(n) = O(g(n))</br>
F(n) =< C.g(n)</br>
  C > 0</br>
  n >= k</br>
  k >= 0</br>
F(n) = 2n<sup>2</sup> + n</br>
2n<sup>2</sup> + n =< c.g(n<sup>2</sup>)</br>
let c = 3 (take any value whose higher approx 2n<sup>2</sup> + n)</br>
2n<sup>2</sup> + n =< 3n<sup>2</sup></br>
  n =< n<sup>2</sup></br>
  1 =< n</br>

##### For example, let n = 5
2n<sup>2</sup> + n =< 3n<sup>2</sup></br>
-> 2(5<sup>2</sup>) + 5 =< 3*5<sup>2</sup></br>
-> 55 =< 75</br>
___






